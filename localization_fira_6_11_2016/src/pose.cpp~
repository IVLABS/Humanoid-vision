
/*
*********************************************************
*							*
*	Author :  Aniket : IvLabs                       *
*                 Radha           
copy                      *
*							*
*********************************************************
*/

#include "Pose.h"


Pose::Pose()
    {
        
	objectPoints.push_back(cv::Point3f(240.f,680.f,715.f));
 	objectPoints.push_back(cv::Point3f(240.f,680.f,215.f));
  	objectPoints.push_back(cv::Point3f(615.f,680.f,215.f));
  	objectPoints.push_back(cv::Point3f(615.f,680.f,715.f));
/*
        cameraIntrinsicParams=Mat(Size(3,3),CV_32FC1);
        //cameraIntrinsicParams=Mat(Size(3,3),CV_64FC1);
   
        cameraIntrinsicParams.at<float>(0,0)=  727.957294f;
	cameraIntrinsicParams.at<float>(0,1)= 0 ;
	cameraIntrinsicParams.at<float>(0,2)= 320.f;//304.729528f;
	cameraIntrinsicParams.at<float>(1,0)= 0 ;
	cameraIntrinsicParams.at<float>(1,1)=  726.232798f;
	cameraIntrinsicParams.at<float>(1,2)= 240.f;//235.217420f;
	cameraIntrinsicParams.at<float>(2,0)= 0 ;
	cameraIntrinsicParams.at<float>(2,1)= 0 ;
	cameraIntrinsicParams.at<float>(2,2)= 1 ;

/*
        cameraIntrinsicParams.at<double>(0,0)=  727.957294;
	cameraIntrinsicParams.at<double>(0,1)= 0 ;
	cameraIntrinsicParams.at<double>(0,2)= 320.0;//304.729528f;
	cameraIntrinsicParams.at<double>(1,0)= 0 ;
	cameraIntrinsicParams.at<double>(1,1)=  726.232798;
	cameraIntrinsicParams.at<double>(1,2)= 240.0;//235.217420f;
	cameraIntrinsicParams.at<double>(2,0)= 0 ;
	cameraIntrinsicParams.at<double>(2,1)= 0 ;
	cameraIntrinsicParams.at<double>(2,2)= 1 ;

*/

 cv::Matx33f cameraIntrinsicParams(727.957294f,0,320.f,
                                   0,726.232798f,240.f,
                                   0,0,1);

 cv::Vec4f distCoeffs(0,0,0,0);


      // distCoeffs=Mat(Size(5,1),CV_32FC1);
       //distCoeffs=Mat::zeros(Size(5,1),CV_64FC1);
    

	/*distCoeffs.at<float>(0,0)= 0.f;
  	distCoeffs.at<float>(0,1)= 0.f;
  	distCoeffs.at<float>(0,2)= 0.f;
  	distCoeffs.at<float>(0,3)= 0.f;
  	distCoeffs.at<float>(0,4)= 0.f;
*/
       
	 

        
    }

double* Pose::contour_detection(Mat threshold, Mat src)
{
   	int flag =0;
   	int largest_area=0;
   	int largest_contour_index;
   	int lowThreshold;
   	int ratio=3;
  	int kernel_size=3;
        int const max_lowThreshold = 100;
        
   	Mat dst(src.rows,src.cols,CV_8UC1,Scalar::all(0));
   	Rect bounding_rect;
   	RotatedRect box;
   	vector<Point>Points ;
   	vector< vector<Point> > contours; // Vector for storing contour
   	vector<Vec4i> hierarchy;
   	Mat detected_edges;
   	blur(threshold, detected_edges, Size(3,3) );

  /// Canny detector
  	Canny( detected_edges, detected_edges, lowThreshold, lowThreshold*ratio, kernel_size );
  	vector< vector<Point> > contours0;
        findContours( detected_edges, contours0, hierarchy,CV_RETR_CCOMP,CV_CHAIN_APPROX_SIMPLE ); // Find the contours in the image
	
	contours.resize(contours0.size());
 	std::vector<Point2f> imagePoints;
        std::vector<Point2f> preciseCorners(4);
    	for( size_t k = 0; k < contours0.size(); k++ )
        {
          double a=contourArea( contours0[k],false); // Find the area of contour
		if(a>largest_area)
	        {
 		largest_area=a;
    		largest_contour_index=k ;
        	approxPolyDP(Mat(contours0[largest_contour_index]), contours[largest_contour_index],9, true);
        	if(contours[k].size()==4)
         	{
                 
 		  
                for (int c=0;c<4;c++)
		{		
		preciseCorners[c] = contours[largest_contour_index][c];
		}
         	
                 cv::cornerSubPix(threshold, preciseCorners, cvSize(5,5),cvSize(-1,-1),  TermCriteria( CV_TERMCRIT_EPS + CV_TERMCRIT_ITER, 40, 0.001 ));
              //  cv::cornerSubPix(threshold, preciseCorners, cvSize(5,5),cvSize(-1,-1), cvTermCriteria(CV_TERMCRIT_ITER,30,0.1));
                
                for (int c=0;c<4;c++)
		{
		contours[largest_contour_index][c] = preciseCorners[c];
		}

                imagePoints.push_back(Point2f(contours[largest_contour_index][0].x,contours[largest_contour_index][0].y));
    		imagePoints.push_back(Point2f(contours[largest_contour_index][1].x,contours[largest_contour_index][1].y));
    		imagePoints.push_back(Point2f(contours[largest_contour_index][2].x,contours[largest_contour_index][2].y));
    		imagePoints.push_back(Point2f(contours[largest_contour_index][3].x,contours[largest_contour_index][3].y));
		
		cout<< " X1 : " <<contours[largest_contour_index][0].x << " Y1 : "<< contours[largest_contour_index][0].y<< endl;
         	cout<< " X2 : " <<contours[largest_contour_index][1].x << " Y2 : "<< contours[largest_contour_index][1].y<< endl;
         	cout<< " X3 : " <<contours[largest_contour_index][2].x << " Y3 : "<< contours[largest_contour_index][2].y<< endl;
         	cout<< " X4 : " <<contours[largest_contour_index][3].x << " Y4 : "<< contours[largest_contour_index][3].y<< endl;
                   

             	Point P1=contours[largest_contour_index][0];
    		Point P2=contours[largest_contour_index][1];
    		Point P3=contours[largest_contour_index][2];
    		Point P4=contours[largest_contour_index][3];


    		line(src,P1,P2, Scalar(0,255,0),1,CV_AA,0);
    		line(src,P2,P3, Scalar(0,255,0),1,CV_AA,0);
    		line(src,P3,P4, Scalar(0,255,0),1,CV_AA,0);
    		line(src,P4,P1, Scalar(0,255,0),1,CV_AA,0);

                flag =1;
          	}
        	}
      }
	// Pose estimation. 

		if(flag==1)
		{
	        double *location=pose_estimation(objectPoints,imagePoints);
	        flag =0;
return location;
	        }


}

double* Pose::pose_estimation(const std::vector<cv::Point3f> &objectPoints,const std::vector<cv::Point2f> &imagePoints)
{
       
	int iterationsCount = 500;        // number of Ransac iterations.
	float reprojectionError = 2.0;    // maximum allowed distance to consider it an inlier.
	float confidence = 0.95;  
        static double position[4];
	// vector of distortion coefficients
    	//cv::Mat rvec = cv::Mat(3, 1, CV_64FC1);          // output rotation vector
    	//cv::Mat tvec = cv::Mat(3, 1, CV_64FC1); 
    Mat rvec,tvec;
     //   rvec.create(3, 1, CV_64FC1);
      //  tvec.create(3, 1, CV_64FC1);
        //rvec=0.0;
        //tvec=0.0;       
    Mat k=Mat(Size(3,3),CV_32FC1);
    k=sum(Mat(cameraIntrinsicParams * cameraIntrinsicParams.t()));
         
 	bool useExtrinsicGuess = false; 
 	int flags=0;
	Mat inliers;
	 

//cv::solvePnPRansac( objectPoints, imagePoints, cameraIntrinsicParams ,distCoeffs, rvec, tvec,useExtrinsicGuess, flags);
 cv::solvePnPRansac( objectPoints, imagePoints, cameraIntrinsicParams ,distCoeffs, rvec, tvec,useExtrinsicGuess, iterationsCount, reprojectionError, confidence ,inliers,flags);

        
      //int method =CV_ITERATIVE;
      //cv::solvePnP(objectPoints,imagePoints, k, distCoeffs,rvec, tvec,useExtrinsicGuess,method);

     	
      cv::Matx33d r;
      cv::Rodrigues(rvec, r);
cout << sum(Mat(r*r.t())) <<endl;
 
       
         Mat distant=Mat(Size(3,3),CV_64FC1);
	 distant =sum(Mat(r*r.t()));
     	//Mat jacobian=Mat(Size(3,1),CV_32FC1);
// Mat distant,jacobian;
	//Rodrigues(rvec,distant,jacobian);
      
        Mat J;
	vector<Point2f> p(4);
	projectPoints(objectPoints,rvec,tvec, cameraIntrinsicParams,  distCoeffs, p, J);

        float sum = 0.;
  	for (size_t i = 0; i <p.size(); i++)
         {
          sum += sqrt((p[i].x - imagePoints[i].x)* (p[i].x - imagePoints[i].x)+(p[i].y - imagePoints[i].y)* (p[i].y - imagePoints[i].y));
         }
       
        

        Mat R= distant.t(); 
    	//cout << "sum=" << sum << endl;
     	cout<<""<<endl;

 //            if(sum<20)
   //            {
               
               cout << "sum=" << sum << endl;
               Mat T = -R * tvec ;
               position[0] =T.at<double>(0,0);
               position[1]=T.at<double>(1,0);
               position[2]=T.at<double>(2,0);
               
     //         }                         
        return position;
}

	







